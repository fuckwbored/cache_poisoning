Веб кэш рекон

1. Поиск файлов, какие кэшируються
Ходим по сайту, тыкаем на всякие страницы, какие скорее всего, статичны. Например: contact-us, FAQ  т.д...
Берем из сурс кода файлы .js .css ... , смотрим на кэш
Ходим на стандартные файлы как robots.txt

Замечаем парочку файлов, какие кэшируються. С головой достататачно файлов 10

2. Анализируем ответы
Индикаторы, какие показывают, что файл закэширован разные. Это может, например:
1. Заголовки по типу X-Cache: HIT
2. Заголовок Age (если не равен 0 всегда)
3. Заголовок Cache-Control
4. Заголовок Expires
5. Много других заголовков .......
6. Статус код 304 в ответе
7. ........... ....

3. На какой основне настроено кэширование
Это может быть:
1. Любой файл в директории (в директории /images/* любые файлы, даже 404 кэшируються)
2. На основне названий файлов/файлов
site.com/robots.txt = cached
site.com/images/tralala.file = not cached, 404
site.com/images/robots.txt = cached, 404
3. На основне расширений (брутим такие через intruder)
site.com/random.zip = 404, not cached
site.com/random.js = 404, cached

4. Ищем по всему сайту cache oracle и играем с ним, чтобы понять, как работает кэш (URL декодиим, пробуем двойные слэши и т д)
На нескольких кэш эндпоинтах и орканулах мы пробвем получить cache key, например в Akami:

==============================================================================================================================
Pragma: akamai-x-get-cache-key, akamai-x-get-true-cache-key

200 OK
X-Cache-Key: /example.com/index.loggedout.html?akamai-transform=9 cid=__Origin=zxcv
X-Cache-Key-Extended-Internal-Use-Only: /example.com/index.loggedout.html?akamai-transform=9 vcd=1234 cid=__Origin=zxcv
X-True-Cache-Key: /example.com/index.loggedout.html vcd=1234 cid=__Origin=zxcv
==============================================================================================================================


5. Дополнительный поиск забытых файлов
1. Собираем файлы через waymore/katana (обязательно смотрим через waymore какие то параметры, часто параметры аналитики unkeyed)
[NOTE] Waymore может дать забытые файлы, какие лежат пыляться на серваке, но могут быть уязвимы
2. Потом прогоняем через httpx-toolkit -l urls.txt  -irr -silent -json -o out.json (желательно 2-4 раза)
3. В файле out.txt смотрим через CTRL + F заголовки, какие показывают, что файл закэширован

6. Хантимся
Теперь берем для каждой директории (если статик файлы по типу .css .js ...) и сканим на скрытые заголовки или че то такого
Для страниц +- то же самое. Ну вы поняли, как понять, сколько сайтов сканить в каком порядке и как их выбрать корроче ;))))
